---
title: "tarea2"
output: html_document
---


```{r}
#install.packages("ggcorrplot")
library(ggcorrplot)
library(tidyverse)
library(MASS)
source('../../utils/eda_utils.R')
library(reshape2)
library(ggplot2)

```


# Tarea 2 
Usamos los datos de https://archive.ics.uci.edu/ml/machine-learning-databases/housing/.
El objetivo es predecir el valor mediano de las viviendas en áreas del censo
de Estados Unidos, utilizando variables relacionadas con criminalidad, ambiente,
tipo de viviendas, etc.

- Separa la muestra en dos partes: unos 400 para entrenamiento y el resto para prueba.

- Describe las variables en la muestra de prueba (rango, media, mediana, por ejemplo). 

- Construye un modelo lineal para predecir MEDV en términos de las otras variables. Utiliza descenso en gradiente para estimar los coeficientes con los predictores estandarizados. Verifica tus resultados con la función *lm*. 

- Evalúa el error de entrenamiento $\overline{err}$ de tu modelo, y evalúa después la estimación del error de predicción $\hat{Err}$ con la muestra de prueba. 

Utiliza la raíz del la media de los errores al cuadrado.

- (Adicional) Construye un modelo de 1,5,20 y 50  vecinos más cercanos, y evalúa su desempeño. ¿Cuál es la mejor $k$ para reducir el error de prueba?



```{r}
data(Boston)
Boston<-as.tibble(Boston)
Boston
```
## Variable Description

CRIM - per capita crime rate by town
ZN - proportion of residential land zoned for lots over 25,000 sq.ft.
INDUS - proportion of non-retail business acres per town.
CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)
NOX - nitric oxides concentration (parts per 10 million)
RM - average number of rooms per dwelling
AGE - proportion of owner-occupied units built prior to 1940
DIS - weighted distances to five Boston employment centres
RAD - index of accessibility to radial highways
TAX - full-value property-tax rate per $10,000
PTRATIO - pupil-teacher ratio by town
BLACK - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
LSTAT - % lower status of the population
MEDV - Median value of owner-occupied homes in $1000's



## Separa la muestra en dos partes: unos 400 para entrenamiento y el resto para prueba.
```{r}
set.seed(123)
train_ind <- sample(seq_len(nrow(Boston)), size = 400)

train <- sample_n(Boston,size = 400)
test <- setdiff(Boston, train)

# Standardization 

Boston_s <- 
  Boston %>% mutate(id=1:n()) %>% 
  gather(variable, valor, crim:medv) %>%
  group_by(variable) %>% mutate(media = mean(valor), desv = sd(valor)) %>%
  mutate(valor_s = (valor - media)/desv) %>% dplyr::select(id, variable, valor_s) %>%
  tidyr::spread(variable, valor_s) %>% dplyr::select(-id)

test_s <- 
  test %>% mutate(id=1:n()) %>% 
  gather(variable, valor, crim:medv) %>%
  group_by(variable) %>% mutate(media = mean(valor), desv = sd(valor)) %>%
  mutate(valor_s = (valor - media)/desv) %>% dplyr::select(id, variable, valor_s) %>%
  tidyr::spread(variable, valor_s) %>% dplyr::select(-id)

train_s <- 
  train %>% mutate(id=1:n()) %>% 
  gather(variable, valor, crim:medv) %>%
  group_by(variable) %>% mutate(media = mean(valor), desv = sd(valor)) %>%
  mutate(valor_s = (valor - media)/desv) %>% dplyr::select(id, variable, valor_s) %>%
  tidyr::spread(variable, valor_s) %>% dplyr::select(-id)

```

## Describe las variables en la muestra de prueba (rango, media, mediana, por ejemplo). 

```{r}
# General Varible Summary
describe(train)
d <- melt(train)

# Histogram plots
ggplot(d,aes(x = value)) + 
    facet_wrap(~variable,scales = "free_x") + 
    geom_histogram(bins = 8)

```

```{r}
corr <- round(cor(Boston_s), 1)

ggcorrplot(corr, hc.order = TRUE, type = "lower",
   outline.col = "white",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))

```
RM - average number of rooms per dwelling
LSTAT - % lower status of the population
AGE - proportion of owner-occupied units built prior to 1940


## Construye un modelo lineal para predecir MEDV en términos de las otras variables. Utiliza descenso en gradiente para estimar los coeficientes con los predictores estandarizados. Verifica tus resultados con la función *lm*. 
```{r}
x_test <- test_s  %>%  dplyr::select(-medv) #%>% dplyr::select(lstat,ptratio, rm)
y_test <- test_s %>% dplyr::select(medv)
y_test <- as.matrix(y_test)

x_train <- train_s  %>%  dplyr::select(-medv) #%>% dplyr::select(lstat,ptratio, rm)
y_train <- train_s %>% dplyr::select(medv)
y_train <- as.matrix(y_train)


X_train <-as.matrix(sapply(x_train, as.numeric))
X_train <-cbind(rep(1, nrow(X_train)), X_train)

X_test<-as.matrix(sapply(x_test, as.numeric))
X_test<-cbind(rep(1, nrow(X_test)), X_test)


```



```{r}
#Definición de función costo (Squared Cost Function)
compCost<-function(X, y, theta){
   m <- length(y)
   J <- sum((X%*%theta- y)^2)/(2*m)
return(J)
}

# Gradient Descent Function

gradDescent<-function(X, y, theta, alpha, num_iters){
  m <- length(y)
  J_hist <- rep(0, num_iters)
  for(i in 1:num_iters){
    theta <- theta - alpha*(1/m)*(t(X)%*%(X%*%theta - y))
    J_hist[i]  <- compCost(X, y, theta)
    }
  results<-list(theta, J_hist)
  return(results)
}
```



```{r}
#Hay que agregarle una columna de unos
theta<-rep(0,ncol(X_train))
alpha <- .1
num_iters <- 15000
results <- gradDescent(X_train, y_train, theta, alpha, num_iters)
print(results[1])
```



```{r}
# LM verification
mod_pr <- lm( medv ~ ., data = train_s )
round(coefficients(mod_pr), 2)
sm<-summary(mod_pr)
print(sm) 
plot(mod_pr)
```



## Evalúa el error de entrenamiento $\overline{err}$ de tu modelo, y evalúa después la estimación del error de predicción $\hat{Err}$ con la muestra de prueba.  Utiliza la raíz del la media de los errores al cuadrado.
```{r}

# Error de Entrenamiento
fitted.values <- mod_pr$fitted.values
mean((fitted.values - y_train)^2)


# Error de Predicción
fit<-predict(mod_pr, as.data.frame(x_test))
mean((fit - y_test)^2)


```
#(Adicional) Construye un modelo de 1,5,20 y 50 vecinos más cercanos, y evalúa su desempeño. ¿Cuál es la mejor   k k  para reducir el error de prueba?

```{r}
library(class)

pred.1 <- knn(train = X_train, test = X_test,cl = y_train, k=1)
pred.2 <- knn(train = X_train, test = X_test,cl = y_train, k=2)
pred.20 <- knn(train = X_train, test = X_test,cl = y_train, k=20)
pred.50 <- knn(train = X_train, test = X_test,cl = y_train, k=50)
```


